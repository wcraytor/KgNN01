{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Program Overview\n",
    "\n",
    "### What This Program Does\n",
    "- **Classifies interior photos** into 10 room types using deep learning\n",
    "- **Uses transfer learning** with ResNet50 for high accuracy\n",
    "- **Handles variable dataset sizes** with percentage-based sampling\n",
    "- **Optimized for Apple Silicon** (MPS) and NVIDIA GPUs\n",
    "- **Comprehensive evaluation** with per-room accuracy analysis\n",
    "\n",
    "### Room Types Supported\n",
    "```\n",
    "bathroom, bedroom, dining, gaming, kitchen,\n",
    "laundry, living, office, terrace, yard\n",
    "```\n",
    "\n",
    "### Hardware Requirements\n",
    "- **Minimum**: 8GB RAM, CPU training\n",
    "- **Recommended**: 64GB RAM, Apple Silicon or NVIDIA GPU\n",
    "- **Training time**: 2-4 hours for 12,000 photo"
   ],
   "id": "5f74f1c9650ed0ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# MUST BE FIRST - Comprehensive SSL fix for PyTorch model downloads\n",
    "import ssl\n",
    "import urllib.request\n",
    "import certifi\n",
    "\n",
    "# Multiple SSL bypass approaches\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "# Also set urllib's default context\n",
    "import urllib.request\n",
    "ssl_context = ssl.create_default_context()\n",
    "ssl_context.check_hostname = False\n",
    "ssl_context.verify_mode = ssl.CERT_NONE\n",
    "urllib.request.install_opener(urllib.request.build_opener(urllib.request.HTTPSHandler(context=ssl_context)))\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from datetime import datetime\n",
    "os.chdir('/Volumes/Nvme_1/Desktop/github/KgNN01')\n",
    "\n"
   ],
   "id": "e68faa6b78677fea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RoomDataset Class\n",
    "\n",
    "**Purpose**: PyTorch-compatible dataset for batch loading during training\n",
    "\n",
    "\n",
    "```python\n",
    "class RoomDataset(Dataset):\n",
    "    def __init__(self, photo_metadata, transform=None)\n",
    "```\n",
    "\n",
    "**Features**:\n",
    "- **Error recovery**: Handles corrupted images gracefully\n",
    "- **Transform pipeline**: Applies preprocessing and data augmentation\n",
    "- **Memory efficient**: Loads images on-demand during training\n",
    "- **Label mapping**: Converts room names to numerical indices\n",
    "\n",
    "**Transform Pipeline**:\n",
    "- **Training**: Aggressive augmentation (rotation, flipping, color jittering)\n",
    "- **Validation**: Consistent preprocessing only\n",
    "- **Normalization**: ImageNet statistics for transfer learning\n"
   ],
   "id": "dba8fab83e3d3832"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "class RoomPhotoDataset:\n",
    "    \"\"\"\n",
    "    Manages room photos organized in images/<room>/ folders\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_path='images', max_photos_per_room=None, sample_percentage=100, random_seed=42):\n",
    "        \"\"\"\n",
    "        Initialize the room dataset manager\n",
    "\n",
    "        Args:\n",
    "            base_path: Path to images folder containing room subfolders\n",
    "            max_photos_per_room: Maximum number of photos per room (None for all)\n",
    "            sample_percentage: Percentage of photos to use (1-100)\n",
    "            random_seed: For reproducible splits and sampling\n",
    "        \"\"\"\n",
    "        self.base_path = base_path\n",
    "        self.max_photos_per_room = max_photos_per_room\n",
    "        self.sample_percentage = max(1, min(100, sample_percentage))  # Clamp between 1-100\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        # Room types\n",
    "        self.room_types = [\n",
    "            'bathroom', 'bedroom', 'dining', 'gaming', 'kitchen',\n",
    "            'laundry', 'living', 'office', 'terrace', 'yard'\n",
    "        ]\n",
    "\n",
    "        # Create room to index mapping\n",
    "        self.room_to_idx = {room: idx for idx, room in enumerate(self.room_types)}\n",
    "        self.idx_to_room = {idx: room for room, idx in self.room_to_idx.items()}\n",
    "\n",
    "        # Dataset size configurations\n",
    "        self.size_configs = {\n",
    "            'tiny': 100,\n",
    "            'small': 500,\n",
    "            'medium': 1000,\n",
    "            'large': 2000,\n",
    "            'xl': 5000,\n",
    "            'full': None  # Use all available\n",
    "        }\n",
    "\n",
    "        # Split ratios\n",
    "        self.split_ratios = {\n",
    "            'train': 0.7,\n",
    "            'val': 0.15,\n",
    "            'test': 0.15\n",
    "        }\n",
    "\n",
    "        # Load and organize all photos\n",
    "        self.photo_metadata = self._load_photo_metadata()\n",
    "        self._create_splits()\n",
    "\n",
    "    def _load_photo_metadata(self):\n",
    "        \"\"\"Load all photo paths and labels from room folders with optional sampling\"\"\"\n",
    "        # Check if base path exists\n",
    "        if not os.path.exists(self.base_path):\n",
    "            raise FileNotFoundError(f\"Images directory not found: {self.base_path}\")\n",
    "\n",
    "        photos = []\n",
    "        room_counts = {}\n",
    "        total_available = 0\n",
    "        total_sampled = 0\n",
    "\n",
    "        # Set random seed for consistent sampling\n",
    "        np.random.seed(self.random_seed)\n",
    "\n",
    "        print(f\"Sampling {self.sample_percentage}% of available photos...\")\n",
    "\n",
    "        for room_idx, room_type in enumerate(self.room_types):\n",
    "            room_path = os.path.join(self.base_path, room_type)\n",
    "\n",
    "            if not os.path.exists(room_path):\n",
    "                print(f\"Warning: Room folder not found: {room_path}\")\n",
    "                room_counts[room_type] = 0\n",
    "                continue\n",
    "\n",
    "            # Get all photos in this room folder\n",
    "            all_room_photos = []\n",
    "            for file in os.listdir(room_path):\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):\n",
    "                    full_path = os.path.join(room_path, file)\n",
    "                    all_room_photos.append({\n",
    "                        'path': full_path,\n",
    "                        'filename': file,\n",
    "                        'room_type': room_type,\n",
    "                        'label': room_idx,\n",
    "                        'room_folder': room_type\n",
    "                    })\n",
    "\n",
    "            total_available += len(all_room_photos)\n",
    "\n",
    "            # Apply sampling percentage\n",
    "            if self.sample_percentage < 100:\n",
    "                sample_size = max(1, int(len(all_room_photos) * self.sample_percentage / 100))\n",
    "                room_photos = np.random.choice(all_room_photos, size=sample_size, replace=False).tolist()\n",
    "                print(f\"  {room_type}: {len(all_room_photos)} available → {len(room_photos)} sampled ({self.sample_percentage}%)\")\n",
    "            else:\n",
    "                room_photos = all_room_photos\n",
    "                print(f\"  {room_type}: {len(room_photos)} photos (100%)\")\n",
    "\n",
    "            # Apply max_photos_per_room if specified\n",
    "            if self.max_photos_per_room and len(room_photos) > self.max_photos_per_room:\n",
    "                room_photos = np.random.choice(room_photos, self.max_photos_per_room, replace=False).tolist()\n",
    "                print(f\"    Limited to {self.max_photos_per_room} photos per room\")\n",
    "\n",
    "            photos.extend(room_photos)\n",
    "            room_counts[room_type] = len(room_photos)\n",
    "            total_sampled += len(room_photos)\n",
    "\n",
    "        # Check if we found any photos\n",
    "        if len(photos) == 0:\n",
    "            raise ValueError(f\"No image files found in {self.base_path}. \"\n",
    "                           f\"Make sure room folders contain image files.\")\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(photos)\n",
    "\n",
    "        print(f\"\\nDataset Summary:\")\n",
    "        print(f\"Total photos available: {total_available}\")\n",
    "        print(f\"Total photos sampled: {total_sampled} ({self.sample_percentage}%)\")\n",
    "        print(f\"Photos loaded into memory: {len(df)}\")\n",
    "        print(\"\\nRoom distribution after sampling:\")\n",
    "        for room, count in room_counts.items():\n",
    "            print(f\"  {room}: {count} photos\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _create_splits(self):\n",
    "        \"\"\"Create stratified train/val/test splits maintaining room balance\"\"\"\n",
    "        np.random.seed(self.random_seed)\n",
    "\n",
    "        # Stratified split to maintain room balance across splits\n",
    "        train_val, test = train_test_split(\n",
    "            self.photo_metadata,\n",
    "            test_size=self.split_ratios['test'],\n",
    "            stratify=self.photo_metadata['label'],\n",
    "            random_state=self.random_seed\n",
    "        )\n",
    "\n",
    "        train, val = train_test_split(\n",
    "            train_val,\n",
    "            test_size=self.split_ratios['val'] / (1 - self.split_ratios['test']),\n",
    "            stratify=train_val['label'],\n",
    "            random_state=self.random_seed\n",
    "        )\n",
    "\n",
    "        # Add split column\n",
    "        self.photo_metadata.loc[train.index, 'split'] = 'train'\n",
    "        self.photo_metadata.loc[val.index, 'split'] = 'val'\n",
    "        self.photo_metadata.loc[test.index, 'split'] = 'test'\n",
    "\n",
    "        print(\"\\nSplit distribution:\")\n",
    "        split_counts = self.photo_metadata.groupby(['split', 'room_type']).size().unstack(fill_value=0)\n",
    "        print(split_counts)\n",
    "\n",
    "    def get_dataset_subset(self, size='full', split='train'):\n",
    "        \"\"\"\n",
    "        Get a specific subset of the data\n",
    "\n",
    "        Args:\n",
    "            size: 'tiny', 'small', 'medium', 'large', 'xl', or 'full'\n",
    "            split: 'train', 'val', or 'test'\n",
    "\n",
    "        Returns:\n",
    "            DataFrame with the requested subset\n",
    "        \"\"\"\n",
    "        if size not in self.size_configs:\n",
    "            raise ValueError(f\"Size must be one of {list(self.size_configs.keys())}\")\n",
    "\n",
    "        if split not in ['train', 'val', 'test']:\n",
    "            raise ValueError(\"Split must be 'train', 'val', or 'test'\")\n",
    "\n",
    "        # Get photos for this split\n",
    "        split_photos = self.photo_metadata[self.photo_metadata['split'] == split].copy()\n",
    "\n",
    "        # If using full dataset, return all\n",
    "        if size == 'full' or self.size_configs[size] is None:\n",
    "            subset = split_photos\n",
    "        else:\n",
    "            # Calculate how many photos we need for this size and split\n",
    "            total_size = self.size_configs[size]\n",
    "            split_ratio = self.split_ratios[split]\n",
    "            target_count = int(total_size * split_ratio)\n",
    "\n",
    "            # Sample stratified by room type to maintain balance\n",
    "            if len(split_photos) >= target_count:\n",
    "                subset = split_photos.groupby('room_type', group_keys=False).apply(\n",
    "                    lambda x: x.sample(min(len(x), max(1, target_count // len(self.room_types))),\n",
    "                                     random_state=self.random_seed)\n",
    "                ).head(target_count)\n",
    "            else:\n",
    "                subset = split_photos\n",
    "\n",
    "        print(f\"\\n{size.title()} {split} set: {len(subset)} photos\")\n",
    "        room_dist = subset['room_type'].value_counts().to_dict()\n",
    "        print(f\"Room distribution: {room_dist}\")\n",
    "\n",
    "        return subset.reset_index(drop=True)"
   ],
   "id": "8cfd534d5ac74a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.  RoomDataset Class\n",
    "\n",
    "**Purpose**: PyTorch-compatible dataset for batch loading during training\n",
    "\n",
    "```python\n",
    "class RoomDataset(Dataset):\n",
    "    def __init__(self, photo_metadata, transform=None)\n",
    "```\n",
    "\n",
    "**Features**:\n",
    "- **Error recovery**: Handles corrupted images gracefully\n",
    "- **Transform pipeline**: Applies preprocessing and data augmentation\n",
    "- **Memory efficient**: Loads images on-demand during training\n",
    "- **Label mapping**: Converts room names to numerical indices\n",
    "\n",
    "**Transform Pipeline**:\n",
    "- **Training**: Aggressive augmentation (rotation, flipping, color jittering)\n",
    "- **Validation**: Consistent preprocessing only\n",
    "- **Normalization**: ImageNet statistics for transfer learning\n"
   ],
   "id": "54c6067037fb9cf7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "class RoomDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for loading room photos\"\"\"\n",
    "\n",
    "    def __init__(self, photo_metadata, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            photo_metadata: DataFrame with 'path' and 'label' columns\n",
    "            transform: torchvision transforms to apply\n",
    "        \"\"\"\n",
    "        self.photo_metadata = photo_metadata\n",
    "        self.transform = transform\n",
    "\n",
    "        if self.transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.photo_metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.photo_metadata.iloc[idx]\n",
    "\n",
    "        # Load and resize image (1200x1016 -> center crop -> 512x512)\n",
    "        try:\n",
    "            image = Image.open(row['path']).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {row['path']}: {e}\")\n",
    "            # Return a blank image if there's an error\n",
    "            image = Image.new('RGB', (512, 512), color='white')\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, row['label']"
   ],
   "id": "45966fbe069d4ba8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Device Management\n",
    "\n",
    "\n",
    "```python\n",
    "def get_device()\n",
    "```\n",
    "\n",
    "**Purpose**: Automatically detects optimal hardware for training\n",
    "\n",
    "**Priority Order**:\n",
    "1. **MPS** (Apple Silicon) - Metal Performance Shaders\n",
    "2. **CUDA** (NVIDIA GPU) - GPU acceleration\n",
    "3. **CPU** - Fallback option\n",
    "\n",
    "**Output**: `torch.device` object with status message"
   ],
   "id": "90d359bda741c910"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def get_device():\n",
    "    \"\"\"\n",
    "    Get the best available device for training\n",
    "    Prioritizes: MPS (Apple Silicon) > CUDA (NVIDIA) > CPU\n",
    "    \"\"\"\n",
    "    if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using Apple Silicon GPU (Metal Performance Shaders)\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"Using CUDA GPU: {torch.cuda.get_device_name()}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU (no GPU available)\")\n",
    "\n",
    "    return device"
   ],
   "id": "6fb07facba9b92f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "```python\n",
    "def create_optimized_transforms()\n",
    "```\n",
    "\n",
    "**Purpose**: Creates training and validation transform pipelines\n",
    "\n",
    "**Returns**: `(train_transform, val_test_transform)`\n",
    "\n",
    "**Training Transforms** (Data Augmentation):\n",
    "- Resize to accommodate 1200×1016 input images\n",
    "- Center crop to 512×512 (minimal information loss)\n",
    "- Random augmentation: rotation, flipping, color jittering\n",
    "- Normalization for transfer learning\n",
    "\n",
    "**Validation Transforms** (Consistent Processing):\n",
    "- Resize and center crop only\n",
    "- No random augmentation\n",
    "- Same normalization as training"
   ],
   "id": "376dd8e85d715fe7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_optimized_transforms():\n",
    "    \"\"\"Create optimized transforms for better accuracy\"\"\"\n",
    "\n",
    "    # Training transforms with aggressive augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        # Start with your 1200x1016 images\n",
    "        transforms.Resize(600),  # Resize to reasonable size first\n",
    "        transforms.CenterCrop(512),  # Center crop to 512x512 (minimal loss)\n",
    "\n",
    "        # Advanced augmentation for better accuracy\n",
    "        transforms.RandomResizedCrop(512, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "        transforms.RandomGrayscale(p=0.05),\n",
    "\n",
    "        # Convert to tensor and normalize\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Validation/test transforms (no augmentation)\n",
    "    val_test_transform = transforms.Compose([\n",
    "        transforms.Resize(600),\n",
    "        transforms.CenterCrop(512),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    return train_transform, val_test_transform"
   ],
   "id": "c0bfb081e1c400de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "```python\n",
    "def create_dataloaders(dataset_manager, size='full', batch_size=16, num_workers=0)\n",
    "```\n",
    "\n",
    "**Purpose**: Creates PyTorch DataLoaders for efficient batch processing\n",
    "\n",
    "**Parameters**:\n",
    "- `dataset_manager`: RoomPhotoDataset instance\n",
    "- `size`: 'tiny'/'small'/'medium'/'large'/'full'\n",
    "- `batch_size`: Optimized for 64GB systems (default: 16)\n",
    "- `num_workers`: Parallel data loading (0 for stability)\n",
    "\n",
    "**Memory Optimizations**:\n",
    "- Conservative batch sizes for limited RAM\n",
    "- Disabled memory pinning for MPS compatibility\n",
    "- Configurable worker processes\n",
    "\n",
    "**Returns**: Dictionary with 'train', 'val', 'test' DataLoaders"
   ],
   "id": "ae4d6c118723f8a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def create_dataloaders(dataset_manager, size='full', batch_size=16, num_workers=0):\n",
    "    \"\"\"\n",
    "    Create train/val/test dataloaders for room classification\n",
    "\n",
    "    Args:\n",
    "        dataset_manager: RoomPhotoDataset instance\n",
    "        size: Dataset size to use\n",
    "        batch_size: Batch size for dataloaders (optimized for 64GB RAM)\n",
    "        num_workers: Number of workers for data loading\n",
    "\n",
    "    Returns:\n",
    "        dict with 'train', 'val', 'test' dataloaders\n",
    "    \"\"\"\n",
    "\n",
    "    # Get optimized transforms\n",
    "    train_transform, val_test_transform = create_optimized_transforms()\n",
    "\n",
    "    dataloaders = {}\n",
    "\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        # Get subset\n",
    "        subset_metadata = dataset_manager.get_dataset_subset(size, split)\n",
    "\n",
    "        # Choose transform\n",
    "        transform = train_transform if split == 'train' else val_test_transform\n",
    "\n",
    "        # Create dataset\n",
    "        dataset = RoomDataset(subset_metadata, transform=transform)\n",
    "\n",
    "        # Create dataloader (optimized for 64GB memory)\n",
    "        shuffle = (split == 'train')\n",
    "        dataloaders[split] = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=False,  # Don't pin memory for MPS\n",
    "            persistent_workers=num_workers > 0\n",
    "        )\n",
    "\n",
    "    return dataloaders"
   ],
   "id": "763c9bcdd8c76a6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### OptimizedRoomNet Class\n",
    "\n",
    "**Purpose**: Neural network model with transfer learning\n",
    "\n",
    "```python\n",
    "class OptimizedRoomNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_rate=0.5)\n",
    "```\n",
    "\n",
    "**Architecture**:\n",
    "- **Backbone**: ResNet50 (with/without pre-trained weights)\n",
    "- **SSL handling**: Graceful fallback if download fails\n",
    "- **Custom classifier**: Dropout + fully connected layers\n",
    "- **Regularization**: Dropout for overfitting prevention\n",
    "\n",
    "**Model Structure**:\n",
    "```python\n",
    "# Feature extraction: ResNet50 convolutional layers\n",
    "# Classifier head:\n",
    "nn.Sequential(\n",
    "    nn.Dropout(0.5),           # Regularization\n",
    "    nn.Linear(2048, 512),      # Feature compression\n",
    "    nn.ReLU(),                 # Activation\n",
    "    nn.Dropout(0.25),          # Additional regularization\n",
    "    nn.Linear(512, 10)         # Final classification\n",
    ")\n",
    "\n"
   ],
   "id": "34bf4a3410fd46d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class OptimizedRoomNet(nn.Module):\n",
    "    \"\"\"Transfer learning model for room classification with optimizations\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=10, dropout_rate=0.5):\n",
    "        super(OptimizedRoomNet, self).__init__()\n",
    "\n",
    "        # Use pre-trained ResNet50 for transfer learning\n",
    "        self.backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "        # Freeze early layers for faster training and better generalization\n",
    "        for param in list(self.backbone.parameters())[:-20]:\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Replace final layer\n",
    "        num_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate / 2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ],
   "id": "281fe23946c9c0f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Training Pipeline\n",
    "\n",
    "```python\n",
    "def train_model(model, train_loader, val_loader, epochs=20, learning_rate=0.001, device=None)\n",
    "```\n",
    "\n",
    "**Purpose**: Complete training loop with advanced optimizations\n",
    "\n",
    "**Advanced Features**:\n",
    "- **AdamW optimizer** with weight decay for better generalization\n",
    "- **Cosine annealing** learning rate schedule\n",
    "- **Label smoothing** reduces overconfidence\n",
    "- **Gradient clipping** prevents exploding gradients\n",
    "- **Best model saving** based on validation accuracy\n",
    "\n",
    "**Monitoring & Logging**:\n",
    "- Real-time progress display\n",
    "- Automatic generation of `EpochStatistics.log`\n",
    "- Training history tracking (loss, accuracy, learning rate, timing)\n",
    "\n",
    "**Returns**: `(history_dict, best_validation_accuracy)`\n"
   ],
   "id": "216b89c3cc014960"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=20, learning_rate=0.001, device=None):\n",
    "    \"\"\"\n",
    "    Train the model with optimizations and return training history\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Use AdamW with weight decay for better generalization\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "\n",
    "    # Use label smoothing for better generalization\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [],\n",
    "        'epochs': [], 'train_time': [], 'learning_rates': []\n",
    "    }\n",
    "\n",
    "    print(f\"Training for {epochs} epochs on {device}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "\n",
    "    # Initialize epoch statistics log\n",
    "    epoch_log_lines = []\n",
    "    epoch_log_lines.append(f\"Epoch Statistics - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    epoch_log_lines.append(\"=\" * 80)\n",
    "    epoch_log_lines.append(f\"{'Epoch':<6} {'Train Loss':<12} {'Train Acc':<12} {'Val Loss':<12} {'Val Acc':<12} {'LR':<12} {'Time(s)':<8}\")\n",
    "    epoch_log_lines.append(\"-\" * 80)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            train_total += target.size(0)\n",
    "            train_correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = output.max(1)\n",
    "                val_total += target.size(0)\n",
    "                val_correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Calculate metrics\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        train_acc = 100. * train_correct / train_total\n",
    "        val_acc = 100. * val_correct / val_total\n",
    "        epoch_time = time.time() - start_time\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "\n",
    "        # Store history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['epochs'].append(epoch + 1)\n",
    "        history['train_time'].append(epoch_time)\n",
    "        history['learning_rates'].append(current_lr)\n",
    "\n",
    "        # Add to epoch log\n",
    "        epoch_log_line = f\"{epoch+1:<6} {avg_train_loss:<12.4f} {train_acc:<12.2f} {avg_val_loss:<12.4f} {val_acc:<12.2f} {current_lr:<12.6f} {epoch_time:<8.1f}\"\n",
    "        epoch_log_lines.append(epoch_log_line)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Epoch {epoch+1:2d}/{epochs}: \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}% | \"\n",
    "              f\"LR: {current_lr:.6f} | Time: {epoch_time:.1f}s\")\n",
    "\n",
    "    total_time = sum(history['train_time'])\n",
    "    print(f\"\\nTraining completed in {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "\n",
    "    # Add summary to epoch log\n",
    "    epoch_log_lines.append(\"\")\n",
    "    epoch_log_lines.append(\"=\" * 80)\n",
    "    epoch_log_lines.append(f\"Training Summary:\")\n",
    "    epoch_log_lines.append(f\"Total training time: {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
    "    epoch_log_lines.append(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    epoch_log_lines.append(f\"Final training accuracy: {history['train_acc'][-1]:.2f}%\")\n",
    "    epoch_log_lines.append(f\"Final validation accuracy: {history['val_acc'][-1]:.2f}%\")\n",
    "\n",
    "    # Save epoch statistics to file\n",
    "    with open('EpochStatistics.log', 'w') as f:\n",
    "        f.write('\\n'.join(epoch_log_lines))\n",
    "\n",
    "    print(\"Epoch statistics saved to EpochStatistics.log\")\n",
    "\n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Loaded best model weights\")\n",
    "\n",
    "    return history, best_val_acc"
   ],
   "id": "c34a742200719817",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Evaluation & Analysis\n",
    "\n",
    "```python\n",
    "def evaluate_model_and_save_results(model, test_loader, dataset_manager, device, save_path)\n",
    "```\n",
    "\n",
    "**Purpose**: Comprehensive model evaluation with detailed analysis\n",
    "\n",
    "**Generated Outputs**:\n",
    "\n",
    "1. **Main Results** (`room_classification_results.txt`):\n",
    "   - Overall test accuracy\n",
    "   - Scikit-learn classification report\n",
    "   - Confusion matrix\n",
    "   - Sample predictions\n",
    "\n",
    "2. **Per-Room Analysis** (`TestResultsByRoomType.log`):\n",
    "   - Accuracy for each of 10 room types\n",
    "   - Best and worst performing rooms\n",
    "   - Statistical breakdown per category\n",
    "\n",
    "3. **Confusion Matrix** (`room_confusion_matrix.png`):\n",
    "   - Heatmap visualization\n",
    "   - Identification of common misclassifications\n",
    "\n",
    "**Per-Room Metrics**:\n",
    "- Individual accuracy for bathroom, kitchen, bedroom, etc.\n",
    "- Performance ranking (which rooms are easiest/hardest to classify)\n",
    "- Sample count and correct predictions per room type"
   ],
   "id": "acfe9a20f7fbce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def evaluate_model_and_save_results(model, test_loader, dataset_manager, device, save_path='room_predictions.txt'):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set and save predictions vs actual\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_actuals = []\n",
    "    all_paths = []\n",
    "\n",
    "    # Track per-room accuracy\n",
    "    room_correct = defaultdict(int)\n",
    "    room_total = defaultdict(int)\n",
    "\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    print(\"Evaluating model on test set...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            _, predicted = output.max(1)\n",
    "\n",
    "            test_total += target.size(0)\n",
    "            test_correct += predicted.eq(target).sum().item()\n",
    "\n",
    "            # Store predictions and actuals\n",
    "            batch_predictions = predicted.cpu().numpy()\n",
    "            batch_actuals = target.cpu().numpy()\n",
    "\n",
    "            all_predictions.extend(batch_predictions)\n",
    "            all_actuals.extend(batch_actuals)\n",
    "\n",
    "            # Track per-room accuracy\n",
    "            for pred, actual in zip(batch_predictions, batch_actuals):\n",
    "                room_name = dataset_manager.idx_to_room[actual]\n",
    "                room_total[room_name] += 1\n",
    "                if pred == actual:\n",
    "                    room_correct[room_name] += 1\n",
    "\n",
    "    test_acc = 100. * test_correct / test_total\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "    # Convert indices to room names\n",
    "    predicted_rooms = [dataset_manager.idx_to_room[idx] for idx in all_predictions]\n",
    "    actual_rooms = [dataset_manager.idx_to_room[idx] for idx in all_actuals]\n",
    "\n",
    "    # Calculate per-room accuracies\n",
    "    room_accuracies = {}\n",
    "    for room in dataset_manager.room_types:\n",
    "        if room_total[room] > 0:\n",
    "            room_accuracies[room] = 100. * room_correct[room] / room_total[room]\n",
    "        else:\n",
    "            room_accuracies[room] = 0.0\n",
    "\n",
    "    # Create detailed report\n",
    "    report_lines = []\n",
    "    report_lines.append(f\"Room Classification Results - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    report_lines.append(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "    report_lines.append(f\"Total Test Images: {len(all_predictions)}\")\n",
    "    report_lines.append(\"\")\n",
    "\n",
    "    # Classification report\n",
    "    report_lines.append(\"Detailed Classification Report:\")\n",
    "    report_lines.append(\"-\" * 40)\n",
    "    class_report = classification_report(actual_rooms, predicted_rooms, target_names=dataset_manager.room_types)\n",
    "    report_lines.append(class_report)\n",
    "    report_lines.append(\"\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    report_lines.append(\"Confusion Matrix:\")\n",
    "    report_lines.append(\"-\" * 20)\n",
    "    cm = confusion_matrix(actual_rooms, predicted_rooms, labels=dataset_manager.room_types)\n",
    "\n",
    "    # Create a formatted confusion matrix\n",
    "    cm_df = pd.DataFrame(cm, index=dataset_manager.room_types, columns=dataset_manager.room_types)\n",
    "    report_lines.append(str(cm_df))\n",
    "    report_lines.append(\"\")\n",
    "\n",
    "    # Individual predictions (first 100 for brevity)\n",
    "    report_lines.append(\"Sample Predictions (first 100):\")\n",
    "    report_lines.append(\"-\" * 35)\n",
    "    report_lines.append(f\"{'Actual':<12} {'Predicted':<12} {'Correct'}\")\n",
    "    report_lines.append(\"-\" * 35)\n",
    "\n",
    "    for i in range(min(100, len(actual_rooms))):\n",
    "        correct = \"✓\" if actual_rooms[i] == predicted_rooms[i] else \"✗\"\n",
    "        report_lines.append(f\"{actual_rooms[i]:<12} {predicted_rooms[i]:<12} {correct}\")\n",
    "\n",
    "    # Save main results to file\n",
    "    with open(save_path, 'w') as f:\n",
    "        f.write('\\n'.join(report_lines))\n",
    "\n",
    "    print(f\"Results saved to {save_path}\")\n",
    "\n",
    "    # Save per-room test results to separate file\n",
    "    room_results_lines = []\n",
    "    room_results_lines.append(f\"Test Results by Room Type - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    room_results_lines.append(\"=\" * 60)\n",
    "    room_results_lines.append(f\"Overall Test Accuracy: {test_acc:.2f}%\")\n",
    "    room_results_lines.append(\"\")\n",
    "    room_results_lines.append(\"Per-Room Test Accuracy:\")\n",
    "    room_results_lines.append(\"-\" * 40)\n",
    "    room_results_lines.append(f\"{'Room Type':<15} {'Correct':<8} {'Total':<8} {'Accuracy':<10}\")\n",
    "    room_results_lines.append(\"-\" * 40)\n",
    "\n",
    "    for room in sorted(dataset_manager.room_types):\n",
    "        correct = room_correct[room]\n",
    "        total = room_total[room]\n",
    "        accuracy = room_accuracies[room]\n",
    "        room_results_lines.append(f\"{room:<15} {correct:<8} {total:<8} {accuracy:<10.2f}%\")\n",
    "\n",
    "    room_results_lines.append(\"\")\n",
    "    room_results_lines.append(\"Room Performance Summary:\")\n",
    "    room_results_lines.append(\"-\" * 30)\n",
    "\n",
    "    # Sort rooms by accuracy\n",
    "    sorted_rooms = sorted(room_accuracies.items(), key=lambda x: x[1], reverse=True)\n",
    "    room_results_lines.append(\"Best performing rooms:\")\n",
    "    for room, acc in sorted_rooms[:3]:\n",
    "        room_results_lines.append(f\"  {room}: {acc:.2f}%\")\n",
    "\n",
    "    room_results_lines.append(\"\")\n",
    "    room_results_lines.append(\"Worst performing rooms:\")\n",
    "    for room, acc in sorted_rooms[-3:]:\n",
    "        room_results_lines.append(f\"  {room}: {acc:.2f}%\")\n",
    "\n",
    "    # Save room-specific results\n",
    "    with open('TestResultsByRoomType.log', 'w') as f:\n",
    "        f.write('\\n'.join(room_results_lines))\n",
    "\n",
    "    print(\"Per-room test results saved to TestResultsByRoomType.log\")\n",
    "\n",
    "    # Also create confusion matrix plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Room Classification Confusion Matrix\\nTest Accuracy: {test_acc:.2f}%')\n",
    "    plt.ylabel('Actual Room')\n",
    "    plt.xlabel('Predicted Room')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('room_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return test_acc"
   ],
   "id": "3fd1e9e28933f18b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualization\n",
    "```python\n",
    "def plot_training_history(history, save_path)\n",
    "```\n",
    "\n",
    "**Purpose**: Creates comprehensive training dashboard\n",
    "\n",
    "**Generated Plots**:\n",
    "- **Loss curves**: Training vs validation loss progression\n",
    "- **Accuracy curves**: Training vs validation accuracy over time\n",
    "- **Learning rate schedule**: Cosine annealing visualization\n",
    "- **Training time**: Per-epoch duration analysis\n",
    "\n",
    "**Overfitting Detection**: Visual identification of train/val divergence"
   ],
   "id": "2ea471010d14919f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def plot_training_history(history, save_path='training_history.png'):\n",
    "    \"\"\"Plot training history with optimizations\"\"\"\n",
    "\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    epochs = history['epochs']\n",
    "\n",
    "    # Loss plot\n",
    "    ax1.plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
    "    ax1.plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
    "    ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Accuracy plot\n",
    "    ax2.plot(epochs, history['train_acc'], 'b-', label='Training Accuracy', linewidth=2)\n",
    "    ax2.plot(epochs, history['val_acc'], 'r-', label='Validation Accuracy', linewidth=2)\n",
    "    ax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # Learning rate plot\n",
    "    ax3.plot(epochs, history['learning_rates'], 'g-', linewidth=2)\n",
    "    ax3.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Learning Rate')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    # Training time per epoch\n",
    "    ax4.bar(epochs, history['train_time'], alpha=0.7, color='orange')\n",
    "    ax4.set_title('Training Time per Epoch', fontsize=14, fontweight='bold')\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylabel('Time (seconds)')\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "id": "6c436ef5d409b894",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Main Training Pipeline\n",
    "```python\n",
    "def train_room_classifier(base_path='images', dataset_size='full', epochs=20,\n",
    "                         batch_size=16, sample_percentage=100)\n",
    "```\n",
    "**Purpose: Orchestrates complete workflow from data loading to evaluation\n",
    "**Parameters**:\n",
    "- `base_path`: Location of room photo folders\n",
    "- `dataset_size`: Scale of training data to use\n",
    "- `epochs`: Number of training iterations\n",
    "- `batch_size`: Memory-optimized batch processing\n",
    "- `sample_percentage`: **NEW** - Percentage of available photos to use\n",
    "\n",
    "**Complete Workflow**:\n",
    "1. Dataset loading with optional sampling\n",
    "2. DataLoader creation with memory optimization\n",
    "3. Model initialization with SSL certificate handling\n",
    "4. Training loop with advanced optimizations\n",
    "5. Comprehensive evaluation and metrics\n",
    "6. Automatic file generation and saving\n",
    "\n",
    "**File Outputs**:\n",
    "- `room_classification_results.txt`\n",
    "- `TestResultsByRoomType.log`\n",
    "- `EpochStatistics.log`\n",
    "- `room_training_history.png`\n",
    "- `room_confusion_matrix.png`"
   ],
   "id": "c36582836a3e2e0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def train_room_classifier(base_path='images', dataset_size='full', epochs=20, batch_size=16, sample_percentage=100):\n",
    "    \"\"\"\n",
    "    Complete training pipeline for room classification\n",
    "\n",
    "    Args:\n",
    "        base_path: Path to images folder\n",
    "        dataset_size: 'tiny', 'small', 'medium', 'large', 'xl', or 'full'\n",
    "        epochs: Number of training epochs\n",
    "        batch_size: Batch size for training\n",
    "        sample_percentage: Percentage of available photos to use (1-100)\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"ROOM CLASSIFICATION TRAINING PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Initialize dataset with sampling\n",
    "    print(\"Loading dataset...\")\n",
    "    dataset_manager = RoomPhotoDataset(base_path=base_path, sample_percentage=sample_percentage)\n",
    "\n",
    "    # Create dataloaders\n",
    "    print(f\"\\nCreating dataloaders for {dataset_size} dataset...\")\n",
    "    dataloaders = create_dataloaders(dataset_manager, size=dataset_size, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "    # Get device\n",
    "    device = get_device()\n",
    "\n",
    "    # Create optimized model\n",
    "    print(\"\\nCreating optimized model...\")\n",
    "    model = OptimizedRoomNet(num_classes=len(dataset_manager.room_types))\n",
    "\n",
    "    # Train model\n",
    "    print(\"\\nStarting training...\")\n",
    "    history, best_val_acc = train_model(\n",
    "        model, dataloaders['train'], dataloaders['val'],\n",
    "        epochs=epochs, learning_rate=0.001, device=device\n",
    "    )\n",
    "\n",
    "    # Evaluate on test set\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_acc = evaluate_model_and_save_results(\n",
    "        model, dataloaders['test'], dataset_manager, device,\n",
    "        save_path='room_classification_results.txt'\n",
    "    )\n",
    "\n",
    "    # Plot training history\n",
    "    print(\"\\nPlotting training history...\")\n",
    "    plot_training_history(history, save_path='room_training_history.png')\n",
    "\n",
    "\n",
    "    print(f\"\\nTraining completed!\")\n",
    "    print(f\"Dataset sampling: {sample_percentage}% of available photos\")\n",
    "    print(f\"Total photos used: {len(dataset_manager.photo_metadata)}\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"Final test accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"Results saved to: room_classification_results.txt\")\n",
    "    print(f\"Per-room results: TestResultsByRoomType.log\")\n",
    "    print(f\"Epoch statistics: EpochStatistics.log\")\n",
    "    print(f\"Plots saved to: room_training_history.png, room_confusion_matrix.png\")\n",
    "\n",
    "    return model, history, dataset_manager"
   ],
   "id": "cb4e1dabc262516c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " ## Usage Patterns\n",
    "\n",
    "### Quick Testing (Development)\n",
    "\n",
    "```python\n",
    "# Test with 5% of photos for rapid iteration\n",
    "model, history, dataset_manager = train_room_classifier(\n",
    "    base_path='images/',\n",
    "    sample_percentage=5,    # Only 5% of photos\n",
    "    epochs=3,               # Few epochs for testing\n",
    "    batch_size=8            # Small batch size\n",
    ")\n",
    "```\n",
    "\n",
    "### Medium Experiment\n",
    "\n",
    "```python\n",
    "# Balanced testing with 25% of photos\n",
    "model, history, dataset_manager = train_room_classifier(\n",
    "    base_path='images/',\n",
    "    sample_percentage=25,   # Quarter of dataset\n",
    "    epochs=10,              # Moderate training\n",
    "    batch_size=16\n",
    ")\n",
    "```\n",
    "\n",
    "### Full Production Training\n",
    "\n",
    "```python\n",
    "# Maximum accuracy with all photos\n",
    "model, history, dataset_manager = train_room_classifier(\n",
    "    base_path='images/',\n",
    "    sample_percentage=100,  # All available photos\n",
    "    epochs=20,              # Full training\n",
    "    batch_size=16           # Optimized for 64GB RAM\n",
    ")\n",
    "```\n",
    "\n",
    "---"
   ],
   "id": "4da91355635a091"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Run complete training pipeline\n",
    "    # Adjust batch_size based on your 64GB memory - start with 16\n",
    "    model, history, dataset_manager = train_room_classifier(\n",
    "        base_path='/Volumes/Nvme_1/Desktop/github/KgNN01/images/',\n",
    "        dataset_size='full',  # Use all photos\n",
    "        epochs=20,\n",
    "        batch_size=16,  # Optimized for 64GB memory\n",
    "        sample_percentage=25\n",
    "    )\n",
    "\n",
    "    print(\"\\nRoom types learned:\")\n",
    "    for i, room in enumerate(dataset_manager.room_types):\n",
    "        print(f\"  {i}: {room}\")"
   ],
   "id": "926a56d32e183900",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Test Functions\n",
    "\n",
    "### Individual Component Testing\n",
    "\n",
    "**Purpose**: Test each component independently during development\n",
    "\n",
    "```python\n",
    "def test_dataset_loading(base_path, sample_percentage=1)\n",
    "def test_model_creation(num_classes=10)\n",
    "def test_dataloader_creation(dataset_manager, batch_size=2)\n",
    "def test_device_detection()\n",
    "def test_training_step(model, dataloaders, device)\n",
    "def test_evaluation_step(model, dataloaders, device)\n",
    "```\n",
    "\n",
    "**Usage in Jupyter**:\n",
    "```python\n",
    "# Cell 1: Test dataset loading\n",
    "dataset = test_dataset_loading('images/', sample_percentage=1)\n",
    "\n",
    "# Cell 2: Test model creation\n",
    "model = test_model_creation()\n",
    "\n",
    "# Cell 3: Test device detection\n",
    "device = test_device_detection()\n",
    "\n",
    "# Cell 4: Test complete pipeline\n",
    "success = test_training_step(model, dataloaders, device)\n",
    "```\n",
    "\n",
    "### Comprehensive Testing\n",
    "\n",
    "```python\n",
    "def run_comprehensive_test(base_path, sample_percentage=0.5)\n",
    "```\n",
    "\n",
    "**Purpose**: Validates entire pipeline with minimal data\n",
    "\n",
    "**Test Coverage**:\n",
    "- Device detection and PyTorch operations\n",
    "- Dataset loading and train/val/test splitting\n",
    "- Model creation and forward pass\n",
    "- DataLoader functionality and batch loading\n",
    "- Training step mechanics and optimization\n",
    "- Evaluation pipeline and metrics calculation\n",
    "\n",
    "**Output**: Pass/fail status for each component + overall summary\n",
    "\n",
    "---\n",
    "\n",
    "## Expected Performance\n",
    "\n",
    "### Accuracy Ranges\n",
    "- **Training from scratch**: 75-85% test accuracy\n",
    "- **With transfer learning**: 85-95% test accuracy\n",
    "- **Dataset size impact**: ~2-5% improvement from 25% to 100% of photos\n",
    "\n",
    "### Training Times (M2 Ultra, 64GB)\n",
    "- **5% dataset, 3 epochs**: ~15 minutes\n",
    "- **25% dataset, 10 epochs**: ~90 minutes\n",
    "- **100% dataset, 20 epochs**: ~3 hours\n",
    "\n",
    "### Memory Usage\n",
    "- **Recommended batch size**: 16 (for 64GB systems)\n",
    "- **Peak memory**: ~20-30GB during training\n",
    "- **Storage**: ~2-4GB for 12,000 photos\n",
    "\n",
    "---\n",
    "\n",
    "## Technical Dependencies\n",
    "\n",
    "### Required Libraries\n",
    "```python\n",
    "torch >= 1.12.0          # Neural network framework\n",
    "torchvision >= 0.13.0    # Computer vision utilities\n",
    "scikit-learn >= 1.0.0    # Evaluation metrics\n",
    "matplotlib >= 3.5.0      # Plotting and visualization\n",
    "seaborn >= 0.11.0        # Statistical visualization\n",
    "pandas >= 1.3.0          # Data manipulation\n",
    "Pillow >= 8.0.0          # Image processing\n",
    "```\n",
    "\n",
    "### Folder Structure Expected\n",
    "```\n",
    "images/\n",
    "├── bathroom/\n",
    "│   ├── photo001.jpg\n",
    "│   └── photo002.jpg\n",
    "├── bedroom/\n",
    "├── dining/\n",
    "├── gaming/\n",
    "├── kitchen/\n",
    "├── laundry/\n",
    "├── living/\n",
    "├── office/\n",
    "├── terrace/\n",
    "└── yard/\n",
    "```\n",
    "\n",
    "### SSL Certificate Handling\n",
    "- Automatic bypass for PyTorch model downloads\n",
    "- Graceful fallback to training from scratch\n",
    "- No manual certificate configuration required\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**Memory Errors**: Reduce `batch_size` from 16 to 8 or 4\n",
    "**SSL Certificate Errors**: Code includes automatic bypass\n",
    "**No GPU Detected**: Will automatically fall back to CPU training\n",
    "**Missing Room Folders**: Warning message, continues with available rooms\n",
    "**Corrupted Images**: Automatic error recovery with placeholder images\n",
    "\n",
    "### Performance Optimization\n",
    "\n",
    "**For Faster Training**:\n",
    "- Use smaller `sample_percentage` during development\n",
    "- Reduce `epochs` for quick testing\n",
    "- Increase `batch_size` if you have more RAM\n",
    "\n",
    "**For Better Accuracy**:\n",
    "- Use `sample_percentage=100` for full dataset\n",
    "- Increase `epochs` to 25-30 if not overfitting\n",
    "- Ensure balanced room distribution in your photos\n"
   ],
   "id": "72122b649342e811"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test Functions for Room Classification Program\n",
    "# Use these in separate Jupyter cells to test individual components\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def test_dataset_loading(base_path='images/', sample_percentage=1, verbose=True):\n",
    "    \"\"\"\n",
    "    Test the RoomPhotoDataset class with minimal parameters\n",
    "\n",
    "    Args:\n",
    "        base_path: Path to images folder\n",
    "        sample_percentage: Very small percentage for quick testing\n",
    "        verbose: Print detailed information\n",
    "\n",
    "    Returns:\n",
    "        dataset_manager: Loaded dataset for further testing\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"TESTING DATASET LOADING\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        # Create dataset with minimal photos\n",
    "        dataset_manager = RoomPhotoDataset(\n",
    "            base_path=base_path,\n",
    "            sample_percentage=sample_percentage,\n",
    "            random_seed=42\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n✅ Dataset loaded successfully!\")\n",
    "            print(f\"Total photos: {len(dataset_manager.photo_metadata)}\")\n",
    "            print(f\"Room types: {len(dataset_manager.room_types)}\")\n",
    "            print(f\"Sample splits:\")\n",
    "            print(dataset_manager.photo_metadata['split'].value_counts())\n",
    "\n",
    "            # Show room distribution\n",
    "            print(f\"\\nRoom distribution:\")\n",
    "            room_counts = dataset_manager.photo_metadata['room_type'].value_counts()\n",
    "            for room, count in room_counts.items():\n",
    "                print(f\"  {room}: {count} photos\")\n",
    "\n",
    "        return dataset_manager\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Dataset loading failed: {e}\")\n",
    "        return None"
   ],
   "id": "30d89154f9246e50",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def test_model_creation(num_classes=10, verbose=True):\n",
    "    \"\"\"\n",
    "    Test OptimizedRoomNet model creation and forward pass\n",
    "\n",
    "    Args:\n",
    "        num_classes: Number of room types\n",
    "        verbose: Print detailed information\n",
    "\n",
    "    Returns:\n",
    "        model: Created model for further testing\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"TESTING MODEL CREATION\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        # Create model\n",
    "        model = OptimizedRoomNet(num_classes=num_classes, dropout_rate=0.3)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"✅ Model created successfully!\")\n",
    "\n",
    "            # Count parameters\n",
    "            total_params = sum(p.numel() for p in model.parameters())\n",
    "            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "            print(f\"Total parameters: {total_params:,}\")\n",
    "            print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "        # Test forward pass with dummy data\n",
    "        model.eval()\n",
    "        dummy_input = torch.randn(2, 3, 512, 512)  # Small batch for testing\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(dummy_input)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"✅ Forward pass successful!\")\n",
    "            print(f\"Input shape: {dummy_input.shape}\")\n",
    "            print(f\"Output shape: {output.shape}\")\n",
    "            print(f\"Output range: [{output.min().item():.3f}, {output.max().item():.3f}]\")\n",
    "\n",
    "        return model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Model creation failed: {e}\")\n",
    "        return None"
   ],
   "id": "6e2e35ac78459f0",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def test_dataloader_creation(dataset_manager, batch_size=2, verbose=True):\n",
    "    \"\"\"\n",
    "    Test DataLoader creation and batch loading\n",
    "\n",
    "    Args:\n",
    "        dataset_manager: RoomPhotoDataset instance\n",
    "        batch_size: Small batch size for testing\n",
    "        verbose: Print detailed information\n",
    "\n",
    "    Returns:\n",
    "        dataloaders: Dictionary of train/val/test dataloaders\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"TESTING DATALOADER CREATION\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        # Create dataloaders with minimal parameters\n",
    "        dataloaders = create_dataloaders(\n",
    "            dataset_manager,\n",
    "            size='tiny',  # Use smallest dataset size\n",
    "            batch_size=batch_size,\n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"✅ DataLoaders created successfully!\")\n",
    "            for split, loader in dataloaders.items():\n",
    "                print(f\"{split} loader: {len(loader)} batches, {len(loader.dataset)} samples\")\n",
    "\n",
    "        # Test loading one batch from each split\n",
    "        test_results = {}\n",
    "        for split, loader in dataloaders.items():\n",
    "            try:\n",
    "                batch_images, batch_labels = next(iter(loader))\n",
    "                test_results[split] = {\n",
    "                    'images_shape': batch_images.shape,\n",
    "                    'labels_shape': batch_labels.shape,\n",
    "                    'image_range': (batch_images.min().item(), batch_images.max().item()),\n",
    "                    'unique_labels': torch.unique(batch_labels).tolist()\n",
    "                }\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"✅ {split} batch loaded:\")\n",
    "                    print(f\"  Images: {batch_images.shape}\")\n",
    "                    print(f\"  Labels: {batch_labels.shape}\")\n",
    "                    print(f\"  Unique labels: {test_results[split]['unique_labels']}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Failed to load {split} batch: {e}\")\n",
    "\n",
    "        return dataloaders\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ DataLoader creation failed: {e}\")\n",
    "        return None"
   ],
   "id": "59f3a5b6fb8db7c",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def test_device_detection(verbose=True):\n",
    "    \"\"\"\n",
    "    Test device detection and basic PyTorch operations\n",
    "\n",
    "    Args:\n",
    "        verbose: Print detailed information\n",
    "\n",
    "    Returns:\n",
    "        device: Detected device\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"TESTING DEVICE DETECTION\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        device = get_device()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"✅ Device detected: {device}\")\n",
    "\n",
    "            # Test basic operations on device\n",
    "            test_tensor = torch.randn(10, 10).to(device)\n",
    "            result = torch.matmul(test_tensor, test_tensor.T)\n",
    "\n",
    "            print(f\"✅ Basic tensor operations successful on {device}\")\n",
    "            print(f\"Test tensor shape: {test_tensor.shape}\")\n",
    "            print(f\"Result shape: {result.shape}\")\n",
    "\n",
    "            # Memory info for GPU devices\n",
    "            if device.type == 'cuda':\n",
    "                print(f\"GPU memory allocated: {torch.cuda.memory_allocated(device) / 1024**2:.1f} MB\")\n",
    "            elif device.type == 'mps':\n",
    "                print(\"MPS device ready for training\")\n",
    "\n",
    "        return device\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Device detection failed: {e}\")\n",
    "        return torch.device('cpu')"
   ],
   "id": "b590bf8682b5edaa",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def test_training_step(model, dataloaders, device, verbose=True):\n",
    "    \"\"\"\n",
    "    Test a single training step to verify the training pipeline\n",
    "\n",
    "    Args:\n",
    "        model: OptimizedRoomNet model\n",
    "        dataloaders: Dictionary of dataloaders\n",
    "        device: PyTorch device\n",
    "        verbose: Print detailed information\n",
    "\n",
    "    Returns:\n",
    "        bool: True if training step successful\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"TESTING TRAINING STEP\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        model = model.to(device)\n",
    "        model.train()\n",
    "\n",
    "        # Setup training components\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "        # Get a training batch\n",
    "        train_loader = dataloaders['train']\n",
    "        batch_images, batch_labels = next(iter(train_loader))\n",
    "        batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Batch loaded: {batch_images.shape} images, {batch_labels.shape} labels\")\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_images)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Forward pass completed: loss = {loss.item():.4f}\")\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        accuracy = predicted.eq(batch_labels).sum().item() / batch_labels.size(0)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"✅ Training step successful!\")\n",
    "            print(f\"Loss: {loss.item():.4f}\")\n",
    "            print(f\"Batch accuracy: {accuracy:.2%}\")\n",
    "            print(f\"Predictions: {predicted.tolist()}\")\n",
    "            print(f\"Actual labels: {batch_labels.tolist()}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Training step failed: {e}\")\n",
    "        return False"
   ],
   "id": "bc5379138a9bd515",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def test_evaluation_step(model, dataloaders, device, verbose=True):\n",
    "    \"\"\"\n",
    "    Test model evaluation on validation data\n",
    "\n",
    "    Args:\n",
    "        model: OptimizedRoomNet model\n",
    "        dataloaders: Dictionary of dataloaders\n",
    "        device: PyTorch device\n",
    "        verbose: Print detailed information\n",
    "\n",
    "    Returns:\n",
    "        dict: Evaluation metrics\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"TESTING EVALUATION STEP\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        model.eval()\n",
    "        val_loader = dataloaders['val']\n",
    "\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_loss = 0\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_images, batch_labels in val_loader:\n",
    "                batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
    "\n",
    "                outputs = model(batch_images)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_correct += predicted.eq(batch_labels).sum().item()\n",
    "                total_samples += batch_labels.size(0)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        accuracy = total_correct / total_samples\n",
    "        avg_loss = total_loss / len(val_loader)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"✅ Evaluation completed!\")\n",
    "            print(f\"Validation accuracy: {accuracy:.2%}\")\n",
    "            print(f\"Validation loss: {avg_loss:.4f}\")\n",
    "            print(f\"Total samples: {total_samples}\")\n",
    "\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'loss': avg_loss,\n",
    "            'total_samples': total_samples\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Evaluation failed: {e}\")\n",
    "        return None"
   ],
   "id": "548a7536749a4238",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def test_mini_training_loop(model, dataloaders, device, epochs=2, verbose=True):\n",
    "    \"\"\"\n",
    "    Test a complete mini training loop with minimal epochs\n",
    "\n",
    "    Args:\n",
    "        model: OptimizedRoomNet model\n",
    "        dataloaders: Dictionary of dataloaders\n",
    "        device: PyTorch device\n",
    "        epochs: Number of test epochs (keep small)\n",
    "        verbose: Print detailed information\n",
    "\n",
    "    Returns:\n",
    "        dict: Training history\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"TESTING MINI TRAINING LOOP\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        model = model.to(device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "\n",
    "            for batch_images, batch_labels in dataloaders['train']:\n",
    "                batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_images)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                train_total += batch_labels.size(0)\n",
    "                train_correct += predicted.eq(batch_labels).sum().item()\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_images, batch_labels in dataloaders['val']:\n",
    "                    batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
    "                    outputs = model(batch_images)\n",
    "                    loss = criterion(outputs, batch_labels)\n",
    "\n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    val_total += batch_labels.size(0)\n",
    "                    val_correct += predicted.eq(batch_labels).sum().item()\n",
    "\n",
    "            # Calculate metrics\n",
    "            train_acc = 100. * train_correct / train_total\n",
    "            val_acc = 100. * val_correct / val_total\n",
    "            avg_train_loss = train_loss / len(dataloaders['train'])\n",
    "            avg_val_loss = val_loss / len(dataloaders['val'])\n",
    "            epoch_time = time.time() - start_time\n",
    "\n",
    "            # Store history\n",
    "            history['train_loss'].append(avg_train_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "            history['val_loss'].append(avg_val_loss)\n",
    "            history['val_acc'].append(val_acc)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}: \"\n",
    "                      f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.1f}% | \"\n",
    "                      f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.1f}% | \"\n",
    "                      f\"Time: {epoch_time:.1f}s\")\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"✅ Mini training loop completed!\")\n",
    "            print(f\"Final train accuracy: {history['train_acc'][-1]:.1f}%\")\n",
    "            print(f\"Final val accuracy: {history['val_acc'][-1]:.1f}%\")\n",
    "\n",
    "        return history\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Mini training loop failed: {e}\")\n",
    "        return None"
   ],
   "id": "13dded51185008c6",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def test_transforms(verbose=True):\n",
    "    \"\"\"\n",
    "    Test the image transform pipeline\n",
    "\n",
    "    Args:\n",
    "        verbose: Print detailed information\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_transform, val_transform)\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"TESTING TRANSFORMS\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        train_transform, val_transform = create_optimized_transforms()\n",
    "\n",
    "        # Create dummy image\n",
    "        dummy_image = torch.randint(0, 255, (1016, 1200, 3), dtype=torch.uint8)  # Simulate your image size\n",
    "        dummy_pil = transforms.ToPILImage()(dummy_image.permute(2, 0, 1))\n",
    "\n",
    "        # Test training transform\n",
    "        train_output = train_transform(dummy_pil)\n",
    "        val_output = val_transform(dummy_pil)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"✅ Transforms created successfully!\")\n",
    "            print(f\"Original image size: {dummy_pil.size}\")\n",
    "            print(f\"Train transform output: {train_output.shape}\")\n",
    "            print(f\"Val transform output: {val_output.shape}\")\n",
    "            print(f\"Train output range: [{train_output.min():.3f}, {train_output.max():.3f}]\")\n",
    "            print(f\"Val output range: [{val_output.min():.3f}, {val_output.max():.3f}]\")\n",
    "\n",
    "        return train_transform, val_transform\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Transform testing failed: {e}\")\n",
    "        return None, None"
   ],
   "id": "9d203e22ae3a3766",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def run_comprehensive_test(base_path='images/', sample_percentage=0.5):\n",
    "    \"\"\"\n",
    "    Run all tests in sequence to verify the complete pipeline\n",
    "\n",
    "    Args:\n",
    "        base_path: Path to images folder\n",
    "        sample_percentage: Small percentage for testing\n",
    "\n",
    "    Returns:\n",
    "        bool: True if all tests pass\n",
    "    \"\"\"\n",
    "    print(\"🚀 STARTING COMPREHENSIVE TEST SUITE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    test_results = {}\n",
    "\n",
    "    # Test 1: Device Detection\n",
    "    device = test_device_detection()\n",
    "    test_results['device'] = device is not None\n",
    "\n",
    "    # Test 2: Transforms\n",
    "    train_transform, val_transform = test_transforms()\n",
    "    test_results['transforms'] = train_transform is not None\n",
    "\n",
    "    # Test 3: Dataset Loading\n",
    "    dataset_manager = test_dataset_loading(base_path, sample_percentage)\n",
    "    test_results['dataset'] = dataset_manager is not None\n",
    "\n",
    "    if dataset_manager is None:\n",
    "        print(\"❌ Cannot continue tests without dataset\")\n",
    "        return False\n",
    "\n",
    "    # Test 4: Model Creation\n",
    "    model = test_model_creation()\n",
    "    test_results['model'] = model is not None\n",
    "\n",
    "    if model is None:\n",
    "        print(\"❌ Cannot continue tests without model\")\n",
    "        return False\n",
    "\n",
    "    # Test 5: DataLoader Creation\n",
    "    dataloaders = test_dataloader_creation(dataset_manager, batch_size=2)\n",
    "    test_results['dataloaders'] = dataloaders is not None\n",
    "\n",
    "    if dataloaders is None:\n",
    "        print(\"❌ Cannot continue tests without dataloaders\")\n",
    "        return False\n",
    "\n",
    "    # Test 6: Training Step\n",
    "    training_success = test_training_step(model, dataloaders, device)\n",
    "    test_results['training_step'] = training_success\n",
    "\n",
    "    # Test 7: Evaluation Step\n",
    "    eval_results = test_evaluation_step(model, dataloaders, device)\n",
    "    test_results['evaluation'] = eval_results is not None\n",
    "\n",
    "    # Test 8: Mini Training Loop\n",
    "    history = test_mini_training_loop(model, dataloaders, device, epochs=2)\n",
    "    test_results['training_loop'] = history is not None\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🏁 TEST SUITE SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    passed_tests = sum(test_results.values())\n",
    "    total_tests = len(test_results)\n",
    "\n",
    "    for test_name, passed in test_results.items():\n",
    "        status = \"✅ PASS\" if passed else \"❌ FAIL\"\n",
    "        print(f\"{test_name:<20}: {status}\")\n",
    "\n",
    "    print(f\"\\nOverall: {passed_tests}/{total_tests} tests passed\")\n",
    "\n",
    "    if passed_tests == total_tests:\n",
    "        print(\"🎉 ALL TESTS PASSED! Your pipeline is ready for full training.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"⚠️  Some tests failed. Check the errors above.\")\n",
    "        return False"
   ],
   "id": "4e2e0adc1ddd7e45",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# Usage examples for individual testing:\n",
    "\"\"\"\n",
    "# Cell 1: Test individual components\n",
    "dataset = test_dataset_loading('images/', sample_percentage=1)"
   ],
   "id": "7287d3b6e6cddeb3",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# Cell 2: Test model\n",
    "model = test_model_creation()"
   ],
   "id": "99a9ce50da4a7aa5",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# Cell 3: Test device\n",
    "device = test_device_detection()"
   ],
   "id": "9b2c516ff3ec5368",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# Cell 4: Test dataloaders\n",
    "dataloaders = test_dataloader_creation(dataset, batch_size=2)"
   ],
   "id": "36703dfa5f6154e2",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# Cell 5: Test training step\n",
    "success = test_training_step(model, dataloaders, device)"
   ],
   "id": "a896578b3fba685d",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Cell 6: Run comprehensive test\n",
    "all_passed = run_comprehensive_test('images/', sample_percentage=0.5)\n",
    "\"\"\"\n",
    "\n"
   ],
   "id": "e726476200d06fa3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
